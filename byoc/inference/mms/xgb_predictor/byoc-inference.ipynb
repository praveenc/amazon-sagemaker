{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b5f05e5-bb56-4fdc-be5e-a309987f3477",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SageMaker BYO Inference container \n",
    "\n",
    "- [Multi-model-Server](https://github.com/awslabs/multi-model-server)(MMS), \n",
    "- [Sagemaker-inference-toolkit](https://github.com/aws/sagemaker-inference-toolkit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def65a6-796a-482a-a934-96b77dd93f3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U awscli boto3 sagemaker rich watermark xgboost scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543a963-bfad-41ff-8073-436c0b7be4e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%load_ext rich\n",
    "\n",
    "%watermark -p awscli,boto3,sagemaker,xgboost,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9cc98-cf5b-41a1-b310-7761c0b1fee5",
   "metadata": {},
   "source": [
    "### Build and test custom inference image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248a9da-8078-43d8-8bf0-9e0c71ddd7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba3d14-ea5e-46f8-ab71-446b0ccd01fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build a local image\n",
    "!docker build -t mms ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c9ef3-f4ad-4573-a519-0449509f1672",
   "metadata": {},
   "source": [
    "### Launch Inference container locally\n",
    "\n",
    "- Mount the [models](./models) directory to `/opt/ml/model` directory inside the container\n",
    "- Map container port `8080` to host port `8080`\n",
    "- `docker run --rm -v $(pwd)/models:/opt/ml/model -p 8080:8080 mms`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3232b-9cd6-40d1-904f-dea598a1ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open terminal and run this command to launch container locally\n",
    "# docker run --rm -v $(pwd)/models:/opt/ml/model -p 8080:8080 mms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601829fc-026b-4c41-88f0-dae7c2e4b334",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ping local inference endpoint\n",
    "!curl http://localhost:8080/ping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3218455-7d9e-4ecc-a8b8-08cddd9c70d2",
   "metadata": {},
   "source": [
    "#### Test records for inference can be found in [test.csv](./test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23362150-2d9b-4712-b21c-a3193f1ff1aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Send test records to /invocations on the endpoint\n",
    "!curl --data-raw '-1.3317586042173168,-1.1425409076053987,-1.0579488602777858,-1.177706547272754,-1.130662184748842,-1.1493955859050584,-1.139968767909096,0.0,1.0,0.0' -H 'Content-Type: text/csv' \\\n",
    "-v http://localhost:8080/invocations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd2335-2ba0-4477-ba64-1caeb9bf69be",
   "metadata": {},
   "source": [
    "### Tag and push the local image to private ECR\n",
    "\n",
    "Now tag the `nginx` local image to ECR format `{account_id}.dkr.ecr.{region}.amazonaws.com/{imagename}:{tag}` format\n",
    "\n",
    "Run [./build_n_push.sh](./build_n_push.sh) shell script with image name `nginx` as parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725ea4b-43b7-42b2-b3c0-45b51ff2a686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod +x ./build_n_push.sh\n",
    "!./build_n_push.sh mms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac3c0e5-c312-4f2d-8aef-ca0a9b0fa80a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy your model to SageMaker Endpoint using custom inference image\n",
    "\n",
    "- Step 1: SageMaker session initialize\n",
    "- Step 2: Compress your model to `model.tar.gz` format and upload to s3\n",
    "- Step 3: Create Model object with your custom inference image \n",
    "- Step 4: Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca639e8-5a28-437b-9e4f-3adf4581da43",
   "metadata": {},
   "source": [
    "#### Step 1: Initialize Session and upload model artifacts to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bff45f-56e3-4bc1-90e8-0d9e31def130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import boto3\n",
    "import sagemaker\n",
    "from rich import print\n",
    "from sagemaker import get_execution_role, session\n",
    "from sagemaker.s3 import S3Downloader, S3Uploader, s3_path_join\n",
    "\n",
    "sm_session = session.Session()\n",
    "region = sm_session._region_name\n",
    "role = get_execution_role()\n",
    "bucket = sm_session.default_bucket()\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "prefix = \"sagemaker/abalone\"\n",
    "account_id = boto3.client(\"sts\").get_caller_identity().get(\"Account\")\n",
    "model_s3uri = s3_path_join(f\"s3://{bucket}/{prefix}\", \"models/byoc-demo/mms/xgbpredictor\")\n",
    "\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Bucket: {bucket}\")\n",
    "print(f\"Model base: {model_s3uri}\")\n",
    "\n",
    "model_path = os.path.join(\"./models\", \"xgboost-model\")\n",
    "model_output_path = os.path.join(\"./models\", \"model.tar.gz\")\n",
    "\n",
    "if not os.path.exists(model_output_path):\n",
    "    print(f\"Compressing model to {model_output_path}\")\n",
    "    tar = tarfile.open(model_output_path, \"w:gz\")\n",
    "    tar.add(model_path, arcname=\"xgboost-model\")\n",
    "    tar.close()\n",
    "else:\n",
    "    print(f\"Model file exists: {model_output_path}\")\n",
    "\n",
    "S3Downloader.list(model_s3uri)\n",
    "\n",
    "S3Uploader.upload(\n",
    "    local_path=model_output_path,\n",
    "    desired_s3_uri=model_s3uri,\n",
    "    sagemaker_session=sm_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6be1a6f-bb8e-4c9d-a8ae-76569d54bc51",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: Create model object with custom inference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c37340-474b-4c37-b7af-d3063235c57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "\n",
    "image_name = \"mms\"\n",
    "ecr_image = f\"{account_id}.dkr.ecr.{region}.amazonaws.com/{image_name}:latest\"\n",
    "print(f\"model_image_uri: {ecr_image}\")\n",
    "\n",
    "suffix = f\"{str(uuid4())[:5]}-{datetime.now().strftime('%d%b%Y')}\"\n",
    "\n",
    "model_data_url = s3_path_join(model_s3uri, \"model.tar.gz\")\n",
    "model_name = f\"AbaloneXGB-predictor-{suffix}\"\n",
    "print(f\"Creating model : {model_name} with {model_data_url}\")\n",
    "\n",
    "predictor_model = Model(\n",
    "    image_uri=ecr_image,\n",
    "    name=model_name,\n",
    "    model_data=model_data_url,\n",
    "    role=role,\n",
    "    sagemaker_session=sm_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559ca73-13bc-495b-ab89-a985333239f0",
   "metadata": {},
   "source": [
    "#### Step 3: Deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0f780f-eb9e-48ed-bbd2-7b6167fe40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"Abalone-MMS-EP-{suffix}\"\n",
    "\n",
    "# Ref: https://sagemaker.readthedocs.io/en/stable/api/inference/model.html\n",
    "print(f\"Deploying model: {model_name} to endpoint: {endpoint_name}\")\n",
    "predictor = predictor_model.deploy(\n",
    "    endpoint_name=endpoint_name, initial_instance_count=1, instance_type=\"ml.m5.xlarge\", wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d602bbb1-a2e3-452f-b1c9-a9dac51cd1d5",
   "metadata": {},
   "source": [
    "### Wait for endpoint to be `InService`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0358fb5a-8c43-48e1-88f7-e1f4db2047bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint [b]{endpoint_name}[/b] Status: [i]{status}[/i]\")\n",
    "\n",
    "# Get the waiter object\n",
    "waiter = sm_client.get_waiter(\"endpoint_in_service\")\n",
    "\n",
    "# Apply the waiter on the endpoint\n",
    "waiter.wait(EndpointName=endpoint_name)\n",
    "\n",
    "# Get endpoint status using describe endpoint\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint [b]{endpoint_name}[/b] Status: [i]{status}[/i]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47ec1d6-8f13-4057-885f-6c53ad99dd97",
   "metadata": {},
   "source": [
    "### Test real-time endpoint on SageMaker with inference records\n",
    "[test.csv](./test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3717ff77-2700-4af7-b143-0de0e67bff2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from time import sleep, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "runtime_sm_client = boto3.client(\"sagemaker-runtime\")\n",
    "\n",
    "LOCALDIR = \".\"\n",
    "\n",
    "local_test_dataset = f\"{LOCALDIR}/test.csv\"\n",
    "\n",
    "limit = 10\n",
    "i = 0\n",
    "\n",
    "with open(local_test_dataset, \"r\") as _f:\n",
    "    for row in _f:\n",
    "        if i == 0:\n",
    "            print(f\"Headers\")\n",
    "            print(row)\n",
    "            print(\"---\" * 20)\n",
    "            i += 1\n",
    "        elif i <= limit:\n",
    "            row = row.rstrip(\"\\n\")\n",
    "            splits = row.split(\",\")\n",
    "            # Remove the target column (first column)\n",
    "            label = splits.pop(0)\n",
    "            input_cols = \",\".join(s for s in splits)\n",
    "            prediction = None\n",
    "            try:\n",
    "                print(f\"Invoking EP with record\")\n",
    "                # print(input_cols)\n",
    "                prediction = runtime_sm_client.invoke_endpoint(\n",
    "                    EndpointName=endpoint_name,\n",
    "                    ContentType=\"text/csv\",\n",
    "                    Body=input_cols,\n",
    "                )\n",
    "                # print(prediction[\"Body\"].read())\n",
    "                response = prediction[\"Body\"].read().decode(\"utf-8\")\n",
    "                # print(response)\n",
    "                print(f\"True: {label} | Predicted: {response}\")\n",
    "                i += 1\n",
    "                sleep(0.5)\n",
    "            except Exception as e:\n",
    "                print(f\"Prediction error: {e}\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15fcdb-d4c3-4c52-b4a4-ac04f11c76fe",
   "metadata": {},
   "source": [
    "### Verify Logs emitted by the endpoint in CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1dd365-391a-4797-b4b4-5d74e75dfd85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "logs_client = boto3.client(\"logs\")\n",
    "end_time = datetime.utcnow()\n",
    "start_time = end_time - timedelta(minutes=15)\n",
    "\n",
    "log_group_name = f\"/aws/sagemaker/Endpoints/{endpoint_name}\"\n",
    "log_streams = logs_client.describe_log_streams(logGroupName=log_group_name)\n",
    "log_stream_name = log_streams[\"logStreams\"][0][\"logStreamName\"]\n",
    "\n",
    "# Retrieve the logs\n",
    "logs = logs_client.get_log_events(\n",
    "    logGroupName=log_group_name,\n",
    "    logStreamName=log_stream_name,\n",
    "    startTime=int(start_time.timestamp() * 1000),\n",
    "    endTime=int(end_time.timestamp() * 1000),\n",
    ")\n",
    "\n",
    "# Print the logs\n",
    "for event in logs[\"events\"]:\n",
    "    print(f\"{datetime.fromtimestamp(event['timestamp'] // 1000)}: {event['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d4caf-e665-477d-965d-1ba8cb91bd0a",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffc175-ee55-4dc7-83ec-b306a75978e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Delete endpoint, endpoint_configuration and model\n",
    "print(f\"EP: {endpoint_name}\")\n",
    "\n",
    "try:\n",
    "    print(f\"Deleting endpoint: {endpoint_name}\")\n",
    "    sm_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "except Exception as e:\n",
    "    print(f\"Error deleting EP: {endpoint_name}\\n{e}\")\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
