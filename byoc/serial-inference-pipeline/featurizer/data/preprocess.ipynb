{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65eccb75",
   "metadata": {},
   "source": [
    "## Sample NB to test preprocess logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093ed6a-0496-47eb-b850-e3e04df64c50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U awscli boto3 sagemaker scikit-learn xgboost pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e0b7fb-6713-43a0-80b1-ff815e174c13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U watermark rich --quiet\n",
    "%load_ext watermark\n",
    "%load_ext rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986664b2-ef18-4eb8-be5b-381060e8fe0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%watermark -p awscli,boto3,sagemaker,sklearn,xgboost,pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9a855e-a87c-4883-b860-5d8474ff152c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from io import StringIO\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# import flask\n",
    "# from flask import Flask\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# np.set_printoptions(precision=6)\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(\n",
    "    \"./data//abalone_train_raw.csv\",\n",
    "    header=None,\n",
    "    names=feature_columns_names + [label_column],\n",
    "    dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    ")\n",
    "\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba32f72-9757-4024-973f-4fdf1bd7c0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' with 100 rows\n",
    "# Extract the first row using iloc\n",
    "first_row = df1.iloc[10]\n",
    "\n",
    "# Convert the extracted row to a DataFrame\n",
    "df = first_row.to_frame().T\n",
    "\n",
    "# Now 'first_row_df' contains a new DataFrame with the first row of 'df'\n",
    "# df = df1.copy(deep=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa893b-b3bc-4ec9-847d-a2b87c447c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Received DF\", flush=True)\n",
    "# print(df, flush=True)\n",
    "\n",
    "# if len(df.columns) == len(feature_columns_names) + 1:\n",
    "#     # This is a labelled example, includes the ring label\n",
    "#     print(f\"Labelled\")\n",
    "#     df.columns = feature_columns_names + [label_column]\n",
    "# elif len(df.columns) == len(feature_columns_names):\n",
    "#     # This is an unlabelled example.\n",
    "#     print(f\"Unlabelled\")\n",
    "#     df.columns = feature_columns_names\n",
    "\n",
    "numeric_features = list(feature_columns_names)\n",
    "numeric_features.remove(\"sex\")\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_features = [\"sex\"]\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "print(f\"Running transform on entire dataset df1\")\n",
    "\n",
    "data = preprocess.fit_transform(df1)\n",
    "# print(f\"Data after transform: {np.squeeze(data)}\", flush=True)\n",
    "# print(f\"Data type: {type(data)}\", flush=True)\n",
    "# print(f\"Data shape: {data.shape}\", flush=True)\n",
    "print(data)\n",
    "\n",
    "single_row = preprocess.transform(df)\n",
    "print(f\"--\" * 25)\n",
    "print(single_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055ada3-4f69-4c87-9690-6c8b28fabaf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Create a 2D NumPy array\n",
    "array = np.array(\n",
    "    [\n",
    "        [\n",
    "            -1.3317586042173168,\n",
    "            -1.1425409076053987,\n",
    "            -1.0579488602777858,\n",
    "            -1.177706547272754,\n",
    "            -1.130662184748842,\n",
    "            -1.1493955859050584,\n",
    "            -1.139968767909096,\n",
    "            0.0,\n",
    "            1.0,\n",
    "            0.0,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Convert the 2D NumPy array to a StringIO object in CSV format\n",
    "csv_buffer = io.StringIO()\n",
    "csv_writer = csv.writer(csv_buffer)\n",
    "\n",
    "for row in array:\n",
    "    print(row)\n",
    "    csv_writer.writerow(row)\n",
    "\n",
    "# Reset the buffer's position to the beginning\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Now you can use 'csv_buffer' as a StringIO object in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bb6a5b-babd-4f59-943d-c4f307c9edfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c0284-9b80-48cd-82bc-91c37d4b965f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25380ba5-ba96-4098-94f0-7c1b605fcf45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array = np.array(\n",
    "    [\n",
    "        [\n",
    "            -1.3317586042173168,\n",
    "            -1.1425409076053987,\n",
    "            -1.0579488602777858,\n",
    "            -1.177706547272754,\n",
    "            -1.130662184748842,\n",
    "            -1.1493955859050584,\n",
    "            -1.139968767909096,\n",
    "            0.0,\n",
    "            1.0,\n",
    "            0.0,\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "data = xgb.DMatrix(data=array)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6c176a-b854-4d64-a0c1-941e4eaa412c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Assuming you have a CSV string named 'csv_string'\n",
    "csv_string = \"0.5057643044112818,0.5739700038488806,0.12587805776591277,0.3165182107971498,0.32207651250285446,0.3086720815446205,0.32454880073267034,1.0,0.0,0.0\"\n",
    "\n",
    "# Create a StringIO object from the CSV string\n",
    "csv_buffer = io.StringIO(csv_string)\n",
    "\n",
    "# Read the CSV data into a list of lists\n",
    "csv_reader = csv.reader(csv_buffer)\n",
    "data = [list(map(float, row)) for row in csv_reader]\n",
    "\n",
    "# Convert the list of lists to a NumPy array\n",
    "array = np.array(data)\n",
    "\n",
    "# Now 'array' is a NumPy array containing the data from the CSV string\n",
    "print(array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
